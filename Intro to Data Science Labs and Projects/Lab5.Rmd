---
title: "Lab 5: Scrape website Data"
subtitle: "MTH 365: Intro to Data Science"
author: "Emmanuel Rayappa"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: pdf_document
---

```{r}
library(robotstxt)
library(rvest)
library(tidyverse)
```

## Scrape Job information

> 1. Remove the `, eval = FALSE` in the R code chunk. Following is the information of data scientist jobs in Omaha on the Indeed.com. Try to find out the correct CSS selector to scrape the information of the job's title, company name, location and rating. (Hint: Go to the source page and look for the class name, the format is `.class1` or `.class1.class2`.) Can you combine them into a data table now? why or why not. 

With all the data now being scrapped from the website, we can now place all the data points into a table. It will not work because each values has a different number of entries, which make the table uneven and therefore does not work. 
```{r}
page <- read_html("https://www.indeed.com/jobs?q=data%20scientist&l=Omaha%2C%20NE&vjk=e53ee7b5be3bd219")

title <- page %>% 
  html_nodes(".jobTitle.jobTitle-color-purple") %>%
  html_text()

company <- page %>%
  html_nodes(".companyName") %>%
  html_text()

location <- page %>%
  html_nodes(".companyLocation") %>%
  html_text()

rate <- page %>% 
  html_nodes(".ratingNumber") %>%
  html_text()

```

> 2. Remove the `, eval = FALSE` in the R code chunk. Read following codes, what's the function of the codes?

This code here eliminates cases of empty ratings or cases where ratings are not available. It's used to even out the length of the data. 
```{r}
rate = page %>% html_nodes(".heading6.company_location.tapItem-gutter") 
rate = sapply(rate, function(x){
    x %>%  html_nodes(".ratingsDisplay.withRatingLink") %>% 
      html_text() %>% as.numeric()
  }) %>% sapply( function(x) ifelse(length(x) == 0, NA, x))

```

> 3. Remove the `, eval = FALSE` in the R code chunk. Read following codes, what's the function of the codes?

The function of the code here is to use data that has been scrapped from the indeed website and displays the information about 30 Data Science Jobs in Omaha with information about the Job (Company name, rating, etc)
```{r}
all_jobs = c()
new_urls<- "https://www.indeed.com/jobs?q=data%20scientist&l=Omaha%2C%20NE&vjk=e53ee7b5be3bd219&start="
i<-10
while (i<30) {
  new_webpage<- read_html(paste0(new_urls,i))
  full <- new_webpage %>% 
    html_elements(".jobCard_mainContent") %>%
    html_text()
  all_jobs = c(all_jobs, full)
  i=i+10
}
```

> 4. Combine the title, company name, location and rate (use the one I give to you) into one data table. 

```{r}
indeed_job_information <- tibble(
  title = title, 
  company = company, 
  location = location, 
  rate = rate
  )

```

> 5. Use the `str_detect` in the last lab to filter the job in Omaha and add a new column to indicate whether the job is a data analyst or data scientist.

```{r}
indeed_job_information_omaha <- indeed_job_information %>%
  filter(str_detect(location,"Omaha")) %>%
  mutate(jobType_DS = str_detect(title, "Data Scientist")) %>%
  mutate(jobType_DA = str_detect(title, "Data Analyst"))
  

```

> 6. Calucate the average rating for score for data analyst job and data scientist job. 

```{r}
indeed_job_information_omaha %>%
  group_by(jobType_DS,rate) %>%
 summarize(Nrate = mean(rate))


```

> 7. Do a boxplot data vitualization of the rating for data analyst job and data scientist job. Compare the results, what's your finding? Don't worry if you have seen some weird shape. Look at the data and think why it looks like that. 

It looks like most Data Scientist or Data Analyst jobs have ratings between 3.0 and 4.0. There is no job with a rating of 5.0 and the Data Analyst Jobs have more rating lower than the median. There are no out-liers in either set, which explains why the boxplot looks even. 

```{r}
ggplot(indeed_job_information_omaha, aes(jobType_DS, jobType_DA, x = rate)) + geom_boxplot(aes(fill = jobType_DS))

```

## Read a table

> 8. In some cases, if the website contains a table, you can directly extract the whole table with `html_table()`, instead of `html_text()`. Read following website, find the id of the table from the source code and extract it. In the source code, find the ID of the table and the CSS selector should be `#ID`. 

```{r}
page <- read_html("https://ourworldindata.org/famines#the-our-world-in-data-dataset-of-famines")

table <- page %>%
html_nodes("#tablepress-73") %>%
html_table()

```

> 9. Now try to do some data cleaning. First, generate a smaller dataset with only Year, Country and Excess Mortality midpoint. First, you need to convert the table to be a data frame, then you may want to rename the columns with colnames() function since the original column name contains spaces. 

```{r}
poverty_data_table <-as.data.frame(table) %>%
  select(Year, Country, Excess.Mortality.midpoint)
colnames(poverty_data_table) <- c("Year", "Country", "Excess_Mortality_midpoint")
  
  
  

```

> 10. Numbers are usually recorded as strings. In order to use them later, we need to convert them to numbers. For the Year, we only want to keep the first 4 digits and for Excess Mortality midpoint, we want to remove the commas before we convert them into numeric data. 

>use `substring()` for extract the first 4 digits and use `gsub()` to remove the commas. Following are the examples. Then use `as.numeric` to convert a string to number. 

```{r}
string = "Hello World!"
substring(string, 1, 5)
gsub("!", "", string)
```

```{r}
poverty_data_table$Year <- substring(poverty_data_table$Year, 1, 4)
poverty_data_table$Excess_Mortality_midpoint <- as.numeric(gsub(",", "",poverty_data_table$Excess_Mortality_midpoint))

```

> 11. Now, sort the table by the increasing order of ExcessMortalitymidpoint and show the first ten rows in the table. 

```{r}
poverty_data_table %>% arrange(Excess_Mortality_midpoint) %>% slice_min(Excess_Mortality_midpoint,n = 10,with_ties =  FALSE)
```

-------

Question 2-3 worth 5 points. Other Questions worth 10 points

Your submissions will be assessed on:

1. Correctness of your code or your answer to the questions. (5 pts. per question).
3. Code formatting: consistency, readability, etc. (5 pts. per question).

Total points possible: 100