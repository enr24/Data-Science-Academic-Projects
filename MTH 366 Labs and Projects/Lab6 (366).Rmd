---
title: "Lab 6"
author: "Emmanuel Rayappa"
date: "Updated `r Sys.Date()`"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float: yes
    theme: cosmo
    code_download: yes
subtitle: 'MTH 366: Machine Learning'
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

Answer the questions below (use blockquotes by starting your line with ">" to denote your response). When you're finished:

1.  Change your name in the "author:" space at the top of this document.
2.  Click the "Knit" button at the top to create an {DF/HTML file with your answers.
3.  Review your answers, make any changes as necessary, and re-"Knit".
4.  Save your PDF/HTML file and upload to BlueLine.

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(caret)
```

## Question 1

The `Glass` data set contains measurements on 214 observations containing chemical analyses of several different types of glass. The goal is to identify the type of glass at a crime scene based on forensic evidence.

```{r}
library(mlbench)
data(Glass)
head(Glass)
```

a) Create a suitable testing and training data set.
```{r}
set.seed(366)
TrainID = createDataPartition(Glass$Type, p = 0.7, times = 1, list = FALSE)
Train = Glass[TrainID,]
Test = Glass[-TrainID,]
```

b) Build a classification tree using the training data set to predict the type of glass based on chemical qualities. (Hint: You may want to re-classify the `Type` variable.) Which variables are "important" in your classification tree.

```{r}
table(Glass$Type)

Glass = Glass %>% mutate(class = case_when(Type == 1 ~ "1",
                                           Type == 2 ~ "2",
                                           Type != 1 & Type != 2 ~ "Other"))

head(Glass)

Train = Glass[TrainID,]
Test = Glass[-TrainID,]

tree = train(class~. -Type, data = Train, method = "rpart")
tree$finalModel
library(rattle)
fancyRpartPlot(tree$finalModel)
```

c) Display the first observation in your training data set. Make a prediction for this observation _manually_. Describe how the prediction is being made.

```{r}
Train[1,]
```

d) How accurate is your classification tree on the training data?
> The accuray is 0.63

```{r}
tree
```

e) Build a bagged classification tree. Has bagging improved your model? Explain why or why not.

> Yes, Bagging did improve the model since the baggin method decreases the variance in the modeling and tneds to give more accurate predictions. 

```{r}
bagged= train(class~. -Type, data = Train, method = "treebag")
bagged
```

f) Which variable(s) are most important in the bagged model?

> The most important variables in the bagged model are: Al, Ng, Na, Ri, Ca, and C

```{r}
varImp(bagged)
```

g) Build a random forest classification model. Has this improved your model? Explain why or why not.

> The accuracy now improves to 0.77, which is better than both the Classification tree and bagged mehtod. Random forest only uses part of the variables for each of the trees which increases the correltaion between trees. 

```{r}
rf= train(class~. -Type, data = Train, method = "rf")
rf
```

h) Which variable(s) are most important in the random forest model?

> The most important variables are: Mg, Ai, and Ca. 

```{r}
varImp(rf)
```

i) What chemical elements are most useful for identifying the type of glass at a crime scene? Which of these models do you prefer?

> The Mg and Al are the most useful elements to predict the type of glass at a crime scene. The Random forest tends to be more acuurate between the various models. 

## Question 2 (complete part g by yourself)

In a previous assignment, you considered the wine quality data set. In this study, researchers attempted to predict the quality of a white Vinho Verde based on its chemical properties.

We will start with White wine and predict the quality as a numerical variable

a). Make a plot of wine quality for your data set. What do you observe?

```{r}
white = read.csv("winequality-white.csv", sep = ";")
head(white)
```

b). Plot each input variable against wine quality. What do you observe?

```{r}
white %>% ggplot(aes(y = quality, x = fixed.acidity)) + geom_point() + geom_smooth(method = "lm")
```

c). Create a 70-30 training-testing balanced split.

```{r}
set.seed(366)
TrainID2 = createDataPartition(white$quality, p = 0.7, times = 1, list = FALSE)
Train2 = white[TrainID2,]
Test2 = white[-TrainID2,]
```

d).  Fit a single decision tree to predict $y$. Which variable(s) are important predictors in your single tree? 
> The variables of importance are alcohol and volatile.acidity

```{r}
tree2 = train(quality~.,  data = Train2, method = "rpart")
tree2$finalModel
```

e). Make a visualization of your decision tree.
```{r}
fancyRpartPlot(tree2$finalModel)
```

f). Fit a random forest. Which variable(s) are important predictors in your forest?

> The most important variables in the random forest are: Alcohol, Density, and Free.Sulfur.Dioxide

```{r}
fitControl = trainControl(method = "none")
rf= train(quality~., data = Train2, method = "rf", trControl = fitControl)
rf
varImp(rf)
```

g). Repeat all previous question a-f with Red wine and predict quality as a categorical variable. 
```{r}
red = read.csv("winequality-red.csv")
head(red)
```
> Generally, most of the variables that we comapre have a decent fit, but none of the model stand out spectacularaly in terms of a near perfect fit. 

```{r}
red %>% ggplot(aes(y = quality, x = fixed.acidity)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = volatile.acidity)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = citric.acid)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = residual.sugar)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = chlorides)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = free.sulfur)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = total.sulfur)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = density)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = pH)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = sulfates)) + geom_point() + geom_smooth(method = "lm")
red %>% ggplot(aes(y = quality, x = alcohol)) + geom_point() + geom_smooth(method = "lm")
```

```{r}
set.seed(366)
TrainID3 = createDataPartition(red$quality, p = 0.7, times = 1, list = FALSE)
Train3 = red[TrainID3,]
Test2 = red[-TrainID3,]
```

> The variables that are of importance are alcohol and sulfates. 

```{r}
tree3 = train(quality~.,  data = Train3, method = "rpart")
tree3$finalModel
```
```{r}
fancyRpartPlot(tree2$finalModel)
```
> The variables of importance here are alcohol, sulfates, and volatile.acidity. 

```{r}
fitControl = trainControl(method = "none")
rf= train(quality~., data = Train3, method = "rf", trControl = fitControl)
rf
varImp(rf)
```


## Question 3 (optional)

Consider the Gini index, classification error, and entropy in a classification model with two classes. Create a plot that displays each of these quantities as a function of $\hat{p}_{m1}$. The x-axis should display $\hat{p}_{m1}$, ranging from 0 to 1, and the y-axis should display the value of the Gini index, classification error, and entropy. Compare and contrast these measures.

```{r}
p = seq(0,1,0.001)

gini = p * (1-p) + (1-p)*p
entropy = -p*log(p) - (1-p)* log(1-p)
classError = apply(data.frame(p,1-p), 1, min)

data = tibble(p =p,entropy = entropy, classError = classError, gini = gini)
head(data)

data %>% ggplot(aes(x = p, y = gini), color =) + geom_line() +geom_line(aes(x = p, y = classError), col = "red") + geom_line(aes(x = p, y = entropy), col = "Blue")

```



## Question 4 (optional)

Our lecture/reading on decision trees introduced __out-of-bag error__. Out-of-bag error takes the observations that are not used in a bootstrap resample and uses those to calculate error. On average, how many observations are "out of bag"? To answer, generate a set of 1,000 data points, and take repeated bootstrap resamples. For each bootstrap resample, count how many "unique" observations are included. Repeat this process a sufficient number of times, and plot the distribution. Interpret your plot.

```{r}
# Hint: Use something like this to count the number of unique observations in R.
N <- 1000
data <- 1:N

boot_sample <- sample(data, size=N, replace=TRUE)
n_unique <- length(unique(boot_sample))
```
