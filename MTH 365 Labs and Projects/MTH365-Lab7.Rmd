---
title: 'Lab 7: What makes a good "Vinho Verde"?'
subtitle: "MTH 365: Intro to Data Science"
author: "Emmanuel Rayappa"
date: "`11-5-2021`"
output: pdf_document
---

"Vinho Verde" (Portuguese: "green wine") refers to a Portuguese style of wine that originated in the historic Minho province in the far north of the country. The name literally means "green wine," but translates as "young wine", with wine being released in 3-6 months after the grapes are harvested. They may be red, white, or rose and they are usually consumed soon after bottling.

A group of researchers living in Guimaraes, Portugal used data mining to classify the quality of white and red Vinho Verde wines based on their chemical properties: acidity, sugar content, chlorides, sulfur dioxide, density, etc. We'll look at the data collected on white wines for this lab.

- P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. "Modeling wine preferences by data mining from physicochemical properties." In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.

```{r, message=FALSE, warning=FALSE}
set.seed(365)
library(tidyverse)
white_wine <- read.csv("winequality-white.csv", sep=";")
glimpse(white_wine)
```

> 1. Fit a linear model with response variable as the quality of the wine. Use all the other variables as the predictors. Which variables are associated with wine quality based on the output?

The variables associated with wine quality are: Fixed.acidity, Volatile Acidity, Residual Sugar, Free.sulfur.dioxide,Density,Sulfates,and Alcohol.
```{r}
model1 <- lm(quality~. ,data = white_wine)
summary(model1)

#white_wine_lm <- white_wine %>% 
  #mutate(Wine_quality = predict(model1))
#confusion_test <- tally(Wine_quality~quality, data=white_wine_lm)
#confusion_test

```

Now, we'll consider a "high quality" wine to be one with a rating of 7 or higher. We also seperate the data into train and test set. 

```{r}
set.seed(365)
white_wine2 <- white_wine %>% mutate(high_quality = ifelse(quality >= 7, 'High', 'Low') )
glimpse(white_wine2)
test_id <- sample(1:nrow(white_wine2), size=round(0.20*nrow(white_wine2)))
TEST <- white_wine2[test_id,]
TRAIN <- white_wine2[-test_id,]
```

> 2. Use a classification tree to explain how alcohol content (`alcohol`) affects whether or not a wine is considered high quality on the train dataset. Remember to load the packages you need. 

Of the 3918 wines in the tree, 79% of them are high quality while the remaining 21% are not. 
```{r}
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
tree <- rpart(alcohol~high_quality, data=TRAIN, na.action = na.pass)
fancyRpartPlot(tree)

```

> 3. Make a plot of alcohol content v. wine quality for the training data. Does the plot support your findings with the classfication model?

The plot does appear support the findings (high alcohol, higher quality) with the classification model. However, this visual isn't very easy to understand and shouldn't necessairaly be used.
```{r}
TRAIN %>% ggplot(aes(y = alcohol, x = high_quality)) + geom_boxplot(aes(fill = high_quality)) +  geom_hline(yintercept=c(8,10,12,14), 
             col=c('black','blue', 'green', 'red'))
```

> 4. It looks like the relationship might be a bit more complex. Use a random forest to "select" additional variables to predict the wine quality. (Hint: You'll need to explicitly state that `high_quality` is a factor variable.) Based on the confusion matrix, when does the random forest work well on the training data?

It works fairly well on the training data as the oob error rate is 12.3%
```{r}
library(randomForest)
set.seed(365)
forest <- randomForest(as.factor(high_quality)~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol ,data=TRAIN, 
                       ntree=201, mtry=3)

forest

```

> 5. Which variables are most important in this forest?

The variables of most importance are quality and alcohol.
```{r}
varImpPlot(forest)

```

> 6. Use the two most important variables in a decision tree. What does this tell you about wine quality?

The decision tree here tells that there is indeed a relationship between alcohol and density.
```{r}
tree2 <-rpart(alcohol ~ density, data = TRAIN)
fancyRpartPlot(tree2)

```

> 7. What if we split the wines into three groups? Define "high quality" to be a quality of 7 or more, "medium quality" to be a quality of 6, and "low quality" to be a quality of 5 or less. Use the nested `ifelse` statement below to create a new variable with three ranking classes. How many wines are in each class? You should also create new test/training data sets.

There are 1306 Low quality wines, 861 high quality wines, and 1747 medium quality wines.

```{r}
library(dplyr)
library(mosaic)
set.seed(365)
white_wine2 <- white_wine %>% mutate(quality3 = ifelse(quality >= 7, 'High', 
                                                           ifelse(quality ==6, 'Medium', 'Low')))

test_id <- sample(1:nrow(white_wine2), size=round(0.20*nrow(white_wine2)))
TEST <- white_wine2[test_id,]
TRAIN <- white_wine2[-test_id,]

tree3 <-rpart(as.factor(quality3)~., data = TRAIN, na.action = na.pass)
fancyRpartPlot(tree3)
summary(tree3)

TRAIN <- TRAIN %>% 
  mutate(tree_quality = predict(tree3, type="class"))
confusion_train <- mosaic::tally(tree_quality~quality, data = TRAIN)
confusion_train



```

> 8. Use a random forest to determine which variables might significantly affect quality using the three classes.

The variables that significantly affect the quality are alcohol and density. 
```{r}
forest2 <- randomForest(as.factor(quality3)~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol,data=TRAIN, 
                       ntree=201, mtry=3)

forest2

varImpPlot(forest2)

```

> 9. Fit a decision tree using the two most significant explanatory variables. What can you conclude?

From the tree, we can conclude that if the alcohol content is higher, then the density of the alcohol is also higher.

```{r}
tree4 <-rpart(alcohol~ density, data = TRAIN)
fancyRpartPlot(tree4)

```

> 10. Report the classification accuracy on the test data with the decision tree. 



```{r}
sum(diag(confusion_train))/nrow(TRAIN)
```